# PyTorch ONNX Conversion Report

```
❌ Obtain model graph with `torch.export.export`
✅ Obtain model graph with `torch.export.export(..., strict=False)`
⚪ Obtain model graph with `torch.jit.trace`
❌ Translate the graph into ONNX
⚪ Run `onnx.checker` on the ONNX model
⚪ Execute the model with ONNX Runtime
⚪ Validate model output accuracy
```

## Error messages

```pytb
# ⚠️ Errors from strategy 'TorchExportStrategy': -----------------------

Traceback (most recent call last):

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/fx/interpreter.py", line 167, in run
    self.env[node] = self.run_node(node)
                     ^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py", line 6478, in run_node
    result = super().run_node(n)
             ^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/fx/interpreter.py", line 228, in run_node
    return getattr(self, n.op)(n.target, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/fx/interpreter.py", line 357, in call_module
    return submod(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py", line 453, in __torch_dispatch__
    r = func.decompose(*args, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/_ops.py", line 766, in decompose
    return self._op_dk(dk, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py", line 557, in __torch_dispatch__
    outs_wrapped = pytree.tree_map_only(
                   ^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/utils/_pytree.py", line 1136, in tree_map_only
    return tree_map(map_only(__type_or_types_or_pred)(func), tree, is_leaf=is_leaf)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/utils/_pytree.py", line 964, in tree_map
    return treespec.unflatten(map(func, *flat_args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/utils/_pytree.py", line 803, in unflatten
    leaves = list(leaves)
             ^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/utils/_pytree.py", line 1082, in wrapped
    return func(x)
           ^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py", line 463, in wrap
    return FunctionalTensor(x, self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py", line 176, in __new__
    out._inference_mode_base = mode._storage_to_base[
                               ^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/.pyenv/versions/3.12.7/lib/python3.12/weakref.py", line 415, in __getitem__
    return self.data[ref(key)]
           ~~~~~~~~~^^^^^^^^^^

KeyError: '<weakref at 0x700b0a39cbd0; to \'torch.storage.UntypedStorage\' at 0x700b0b4d3a70>\n\nWhile executing %x_6 : [num_users=1] = call_module[target=L__vocos____modules__backbone___convnext_0_pwconv1](args = (%x_5,), kwargs = {})\nOriginal traceback:\n  File "/home/ubuntu/projects/f5-tts/onnx/convert_vocos.py", line 28, in forward\n    return vocos.decode(x)\n  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context\n    return func(*args, **kwargs)\n  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/pretrained.py", line 112, in decode\n    x = self.backbone(features_input, **kwargs)\n  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/models.py", line 87, in forward\n    x = conv_block(x, cond_embedding_id=bandwidth_id)\n  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py", line 52, in forward\n    x = self.pwconv1(x)\n'


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_capture_strategies.py", line 110, in __call__
    exported_program = self._capture(model, args, kwargs, dynamic_shapes)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_capture_strategies.py", line 145, in _capture
    return torch.export.export(
           ^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/export/__init__.py", line 368, in export
    return _export(
           ^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/export/_trace.py", line 1029, in wrapper
    raise e

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/export/_trace.py", line 1002, in wrapper
    ep = fn(*args, **kwargs)
         ^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/export/exported_program.py", line 122, in wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/export/_trace.py", line 1941, in _export
    export_artifact = export_func(  # type: ignore[operator]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/export/_trace.py", line 1249, in _strict_export
    return _strict_export_lower_to_aten_ir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/export/_trace.py", line 1358, in _strict_export_lower_to_aten_ir
    aten_export_artifact = lower_to_aten_callback(
                           ^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/export/_trace.py", line 736, in _export_to_aten_ir
    gm, graph_signature = transform(aot_export_module)(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py", line 1262, in aot_export_module
    fx_g, metadata, in_spec, out_spec = _aot_export_function(
                                        ^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py", line 1497, in _aot_export_function
    fx_g, meta = create_aot_dispatcher_function(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py", line 524, in create_aot_dispatcher_function
    return _create_aot_dispatcher_function(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py", line 625, in _create_aot_dispatcher_function
    fw_metadata = run_functionalized_fw_and_collect_metadata(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/collect_metadata_analysis.py", line 194, in inner
    flat_f_outs = f(*flat_f_args)
                  ^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/utils.py", line 184, in flat_fn
    tree_out = fn(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py", line 859, in functional_call
    out = PropagateUnbackedSymInts(mod).run(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/fx/interpreter.py", line 175, in run
    raise RuntimeError(*e.args) from e

RuntimeError: <weakref at 0x700b0a39cbd0; to 'torch.storage.UntypedStorage' at 0x700b0b4d3a70>

While executing %x_6 : [num_users=1] = call_module[target=L__vocos____modules__backbone___convnext_0_pwconv1](args = (%x_5,), kwargs = {})
Original traceback:
  File "/home/ubuntu/projects/f5-tts/onnx/convert_vocos.py", line 28, in forward
    return vocos.decode(x)
  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/pretrained.py", line 112, in decode
    x = self.backbone(features_input, **kwargs)
  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/models.py", line 87, in forward
    x = conv_block(x, cond_embedding_id=bandwidth_id)
  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py", line 52, in forward
    x = self.pwconv1(x)




Traceback (most recent call last):

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py", line 553, in _add_nodes
    _handle_call_function_node_with_lowering(

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py", line 444, in _handle_call_function_node_with_lowering
    raise _errors.DispatchError(

torch.onnx._internal.exporter._errors.DispatchError: No ONNX function found for <OpOverload(op='prims.fft_c2r', overload='default')>. Failure message: No decompositions registered for the complex-valued input


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py", line 1141, in export
    onnx_program = _exported_program_to_onnx_program(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py", line 798, in _exported_program_to_onnx_program
    values = _add_nodes(exported_program, model, lower=lower, registry=registry)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py", line 565, in _add_nodes
    raise _errors.ConversionError(

torch.onnx._internal.exporter._errors.ConversionError: Error when translating node %fft_c2r : [num_users=1] = call_function[target=torch.ops.prims.fft_c2r.default](args = (%transpose_20,), kwargs = {dim: [2], last_dim_size: 1024}). See the stack trace for more information.

```

## Exported program

```python
ExportedProgram:
    class GraphModule(torch.nn.Module):
        def forward(self, p_backbone_embed_weight: "f32[512, 100, 7]", p_backbone_embed_bias: "f32[512]", p_backbone_norm_weight: "f32[512]", p_backbone_norm_bias: "f32[512]", p_backbone_convnext_0_gamma: "f32[512]", p_backbone_convnext_0_dwconv_weight: "f32[512, 1, 7]", p_backbone_convnext_0_dwconv_bias: "f32[512]", p_backbone_convnext_0_norm_weight: "f32[512]", p_backbone_convnext_0_norm_bias: "f32[512]", p_backbone_convnext_0_pwconv1_weight: "f32[1536, 512]", p_backbone_convnext_0_pwconv1_bias: "f32[1536]", p_backbone_convnext_0_pwconv2_weight: "f32[512, 1536]", p_backbone_convnext_0_pwconv2_bias: "f32[512]", p_backbone_convnext_1_gamma: "f32[512]", p_backbone_convnext_1_dwconv_weight: "f32[512, 1, 7]", p_backbone_convnext_1_dwconv_bias: "f32[512]", p_backbone_convnext_1_norm_weight: "f32[512]", p_backbone_convnext_1_norm_bias: "f32[512]", p_backbone_convnext_1_pwconv1_weight: "f32[1536, 512]", p_backbone_convnext_1_pwconv1_bias: "f32[1536]", p_backbone_convnext_1_pwconv2_weight: "f32[512, 1536]", p_backbone_convnext_1_pwconv2_bias: "f32[512]", p_backbone_convnext_2_gamma: "f32[512]", p_backbone_convnext_2_dwconv_weight: "f32[512, 1, 7]", p_backbone_convnext_2_dwconv_bias: "f32[512]", p_backbone_convnext_2_norm_weight: "f32[512]", p_backbone_convnext_2_norm_bias: "f32[512]", p_backbone_convnext_2_pwconv1_weight: "f32[1536, 512]", p_backbone_convnext_2_pwconv1_bias: "f32[1536]", p_backbone_convnext_2_pwconv2_weight: "f32[512, 1536]", p_backbone_convnext_2_pwconv2_bias: "f32[512]", p_backbone_convnext_3_gamma: "f32[512]", p_backbone_convnext_3_dwconv_weight: "f32[512, 1, 7]", p_backbone_convnext_3_dwconv_bias: "f32[512]", p_backbone_convnext_3_norm_weight: "f32[512]", p_backbone_convnext_3_norm_bias: "f32[512]", p_backbone_convnext_3_pwconv1_weight: "f32[1536, 512]", p_backbone_convnext_3_pwconv1_bias: "f32[1536]", p_backbone_convnext_3_pwconv2_weight: "f32[512, 1536]", p_backbone_convnext_3_pwconv2_bias: "f32[512]", p_backbone_convnext_4_gamma: "f32[512]", p_backbone_convnext_4_dwconv_weight: "f32[512, 1, 7]", p_backbone_convnext_4_dwconv_bias: "f32[512]", p_backbone_convnext_4_norm_weight: "f32[512]", p_backbone_convnext_4_norm_bias: "f32[512]", p_backbone_convnext_4_pwconv1_weight: "f32[1536, 512]", p_backbone_convnext_4_pwconv1_bias: "f32[1536]", p_backbone_convnext_4_pwconv2_weight: "f32[512, 1536]", p_backbone_convnext_4_pwconv2_bias: "f32[512]", p_backbone_convnext_5_gamma: "f32[512]", p_backbone_convnext_5_dwconv_weight: "f32[512, 1, 7]", p_backbone_convnext_5_dwconv_bias: "f32[512]", p_backbone_convnext_5_norm_weight: "f32[512]", p_backbone_convnext_5_norm_bias: "f32[512]", p_backbone_convnext_5_pwconv1_weight: "f32[1536, 512]", p_backbone_convnext_5_pwconv1_bias: "f32[1536]", p_backbone_convnext_5_pwconv2_weight: "f32[512, 1536]", p_backbone_convnext_5_pwconv2_bias: "f32[512]", p_backbone_convnext_6_gamma: "f32[512]", p_backbone_convnext_6_dwconv_weight: "f32[512, 1, 7]", p_backbone_convnext_6_dwconv_bias: "f32[512]", p_backbone_convnext_6_norm_weight: "f32[512]", p_backbone_convnext_6_norm_bias: "f32[512]", p_backbone_convnext_6_pwconv1_weight: "f32[1536, 512]", p_backbone_convnext_6_pwconv1_bias: "f32[1536]", p_backbone_convnext_6_pwconv2_weight: "f32[512, 1536]", p_backbone_convnext_6_pwconv2_bias: "f32[512]", p_backbone_convnext_7_gamma: "f32[512]", p_backbone_convnext_7_dwconv_weight: "f32[512, 1, 7]", p_backbone_convnext_7_dwconv_bias: "f32[512]", p_backbone_convnext_7_norm_weight: "f32[512]", p_backbone_convnext_7_norm_bias: "f32[512]", p_backbone_convnext_7_pwconv1_weight: "f32[1536, 512]", p_backbone_convnext_7_pwconv1_bias: "f32[1536]", p_backbone_convnext_7_pwconv2_weight: "f32[512, 1536]", p_backbone_convnext_7_pwconv2_bias: "f32[512]", p_backbone_final_layer_norm_weight: "f32[512]", p_backbone_final_layer_norm_bias: "f32[512]", p_head_out_weight: "f32[1026, 512]", p_head_out_bias: "f32[1026]", b_feature_extractor_mel_spec_spectrogram_window: "f32[1024]", b_feature_extractor_mel_spec_mel_scale_fb: "f32[513, 100]", b_head_istft_window: "f32[1024]", x: "f32[512, 100, 7]"):
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:375 in forward, code: return self._conv_forward(input, self.weight, self.bias)
            conv1d: "f32[512, 512, 7]" = torch.ops.aten.conv1d.default(x, p_backbone_embed_weight, p_backbone_embed_bias, [1], [3]);  x = p_backbone_embed_weight = p_backbone_embed_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/models.py:84 in forward, code: x = self.norm(x.transpose(1, 2))
            transpose: "f32[512, 7, 512]" = torch.ops.aten.transpose.int(conv1d, 1, 2);  conv1d = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
            layer_norm: "f32[512, 7, 512]" = torch.ops.aten.layer_norm.default(transpose, [512], p_backbone_norm_weight, p_backbone_norm_bias, 1e-06);  transpose = p_backbone_norm_weight = p_backbone_norm_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/models.py:85 in forward, code: x = x.transpose(1, 2)
            transpose_1: "f32[512, 512, 7]" = torch.ops.aten.transpose.int(layer_norm, 1, 2);  layer_norm = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:375 in forward, code: return self._conv_forward(input, self.weight, self.bias)
            conv1d_1: "f32[512, 512, 7]" = torch.ops.aten.conv1d.default(transpose_1, p_backbone_convnext_0_dwconv_weight, p_backbone_convnext_0_dwconv_bias, [1], [3], [1], 512);  p_backbone_convnext_0_dwconv_weight = p_backbone_convnext_0_dwconv_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:46 in forward, code: x = x.transpose(1, 2)  # (B, C, T) -> (B, T, C)
            transpose_2: "f32[512, 7, 512]" = torch.ops.aten.transpose.int(conv1d_1, 1, 2);  conv1d_1 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
            layer_norm_1: "f32[512, 7, 512]" = torch.ops.aten.layer_norm.default(transpose_2, [512], p_backbone_convnext_0_norm_weight, p_backbone_convnext_0_norm_bias, 1e-06);  transpose_2 = p_backbone_convnext_0_norm_weight = p_backbone_convnext_0_norm_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
            linear: "f32[512, 7, 1536]" = torch.ops.aten.linear.default(layer_norm_1, p_backbone_convnext_0_pwconv1_weight, p_backbone_convnext_0_pwconv1_bias);  layer_norm_1 = p_backbone_convnext_0_pwconv1_weight = p_backbone_convnext_0_pwconv1_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:734 in forward, code: return F.gelu(input, approximate=self.approximate)
            gelu: "f32[512, 7, 1536]" = torch.ops.aten.gelu.default(linear);  linear = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
            linear_1: "f32[512, 7, 512]" = torch.ops.aten.linear.default(gelu, p_backbone_convnext_0_pwconv2_weight, p_backbone_convnext_0_pwconv2_bias);  gelu = p_backbone_convnext_0_pwconv2_weight = p_backbone_convnext_0_pwconv2_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:56 in forward, code: x = self.gamma * x
            mul: "f32[512, 7, 512]" = torch.ops.aten.mul.Tensor(p_backbone_convnext_0_gamma, linear_1);  p_backbone_convnext_0_gamma = linear_1 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:57 in forward, code: x = x.transpose(1, 2)  # (B, T, C) -> (B, C, T)
            transpose_3: "f32[512, 512, 7]" = torch.ops.aten.transpose.int(mul, 1, 2);  mul = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:59 in forward, code: x = residual + x
            add: "f32[512, 512, 7]" = torch.ops.aten.add.Tensor(transpose_1, transpose_3);  transpose_1 = transpose_3 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:375 in forward, code: return self._conv_forward(input, self.weight, self.bias)
            conv1d_2: "f32[512, 512, 7]" = torch.ops.aten.conv1d.default(add, p_backbone_convnext_1_dwconv_weight, p_backbone_convnext_1_dwconv_bias, [1], [3], [1], 512);  p_backbone_convnext_1_dwconv_weight = p_backbone_convnext_1_dwconv_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:46 in forward, code: x = x.transpose(1, 2)  # (B, C, T) -> (B, T, C)
            transpose_4: "f32[512, 7, 512]" = torch.ops.aten.transpose.int(conv1d_2, 1, 2);  conv1d_2 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
            layer_norm_2: "f32[512, 7, 512]" = torch.ops.aten.layer_norm.default(transpose_4, [512], p_backbone_convnext_1_norm_weight, p_backbone_convnext_1_norm_bias, 1e-06);  transpose_4 = p_backbone_convnext_1_norm_weight = p_backbone_convnext_1_norm_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
            linear_2: "f32[512, 7, 1536]" = torch.ops.aten.linear.default(layer_norm_2, p_backbone_convnext_1_pwconv1_weight, p_backbone_convnext_1_pwconv1_bias);  layer_norm_2 = p_backbone_convnext_1_pwconv1_weight = p_backbone_convnext_1_pwconv1_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:734 in forward, code: return F.gelu(input, approximate=self.approximate)
            gelu_1: "f32[512, 7, 1536]" = torch.ops.aten.gelu.default(linear_2);  linear_2 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
            linear_3: "f32[512, 7, 512]" = torch.ops.aten.linear.default(gelu_1, p_backbone_convnext_1_pwconv2_weight, p_backbone_convnext_1_pwconv2_bias);  gelu_1 = p_backbone_convnext_1_pwconv2_weight = p_backbone_convnext_1_pwconv2_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:56 in forward, code: x = self.gamma * x
            mul_1: "f32[512, 7, 512]" = torch.ops.aten.mul.Tensor(p_backbone_convnext_1_gamma, linear_3);  p_backbone_convnext_1_gamma = linear_3 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:57 in forward, code: x = x.transpose(1, 2)  # (B, T, C) -> (B, C, T)
            transpose_5: "f32[512, 512, 7]" = torch.ops.aten.transpose.int(mul_1, 1, 2);  mul_1 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:59 in forward, code: x = residual + x
            add_1: "f32[512, 512, 7]" = torch.ops.aten.add.Tensor(add, transpose_5);  add = transpose_5 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:375 in forward, code: return self._conv_forward(input, self.weight, self.bias)
            conv1d_3: "f32[512, 512, 7]" = torch.ops.aten.conv1d.default(add_1, p_backbone_convnext_2_dwconv_weight, p_backbone_convnext_2_dwconv_bias, [1], [3], [1], 512);  p_backbone_convnext_2_dwconv_weight = p_backbone_convnext_2_dwconv_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:46 in forward, code: x = x.transpose(1, 2)  # (B, C, T) -> (B, T, C)
            transpose_6: "f32[512, 7, 512]" = torch.ops.aten.transpose.int(conv1d_3, 1, 2);  conv1d_3 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
            layer_norm_3: "f32[512, 7, 512]" = torch.ops.aten.layer_norm.default(transpose_6, [512], p_backbone_convnext_2_norm_weight, p_backbone_convnext_2_norm_bias, 1e-06);  transpose_6 = p_backbone_convnext_2_norm_weight = p_backbone_convnext_2_norm_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
            linear_4: "f32[512, 7, 1536]" = torch.ops.aten.linear.default(layer_norm_3, p_backbone_convnext_2_pwconv1_weight, p_backbone_convnext_2_pwconv1_bias);  layer_norm_3 = p_backbone_convnext_2_pwconv1_weight = p_backbone_convnext_2_pwconv1_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:734 in forward, code: return F.gelu(input, approximate=self.approximate)
            gelu_2: "f32[512, 7, 1536]" = torch.ops.aten.gelu.default(linear_4);  linear_4 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
            linear_5: "f32[512, 7, 512]" = torch.ops.aten.linear.default(gelu_2, p_backbone_convnext_2_pwconv2_weight, p_backbone_convnext_2_pwconv2_bias);  gelu_2 = p_backbone_convnext_2_pwconv2_weight = p_backbone_convnext_2_pwconv2_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:56 in forward, code: x = self.gamma * x
            mul_2: "f32[512, 7, 512]" = torch.ops.aten.mul.Tensor(p_backbone_convnext_2_gamma, linear_5);  p_backbone_convnext_2_gamma = linear_5 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:57 in forward, code: x = x.transpose(1, 2)  # (B, T, C) -> (B, C, T)
            transpose_7: "f32[512, 512, 7]" = torch.ops.aten.transpose.int(mul_2, 1, 2);  mul_2 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:59 in forward, code: x = residual + x
            add_2: "f32[512, 512, 7]" = torch.ops.aten.add.Tensor(add_1, transpose_7);  add_1 = transpose_7 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:375 in forward, code: return self._conv_forward(input, self.weight, self.bias)
            conv1d_4: "f32[512, 512, 7]" = torch.ops.aten.conv1d.default(add_2, p_backbone_convnext_3_dwconv_weight, p_backbone_convnext_3_dwconv_bias, [1], [3], [1], 512);  p_backbone_convnext_3_dwconv_weight = p_backbone_convnext_3_dwconv_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:46 in forward, code: x = x.transpose(1, 2)  # (B, C, T) -> (B, T, C)
            transpose_8: "f32[512, 7, 512]" = torch.ops.aten.transpose.int(conv1d_4, 1, 2);  conv1d_4 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
            layer_norm_4: "f32[512, 7, 512]" = torch.ops.aten.layer_norm.default(transpose_8, [512], p_backbone_convnext_3_norm_weight, p_backbone_convnext_3_norm_bias, 1e-06);  transpose_8 = p_backbone_convnext_3_norm_weight = p_backbone_convnext_3_norm_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
            linear_6: "f32[512, 7, 1536]" = torch.ops.aten.linear.default(layer_norm_4, p_backbone_convnext_3_pwconv1_weight, p_backbone_convnext_3_pwconv1_bias);  layer_norm_4 = p_backbone_convnext_3_pwconv1_weight = p_backbone_convnext_3_pwconv1_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:734 in forward, code: return F.gelu(input, approximate=self.approximate)
            gelu_3: "f32[512, 7, 1536]" = torch.ops.aten.gelu.default(linear_6);  linear_6 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
            linear_7: "f32[512, 7, 512]" = torch.ops.aten.linear.default(gelu_3, p_backbone_convnext_3_pwconv2_weight, p_backbone_convnext_3_pwconv2_bias);  gelu_3 = p_backbone_convnext_3_pwconv2_weight = p_backbone_convnext_3_pwconv2_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:56 in forward, code: x = self.gamma * x
            mul_3: "f32[512, 7, 512]" = torch.ops.aten.mul.Tensor(p_backbone_convnext_3_gamma, linear_7);  p_backbone_convnext_3_gamma = linear_7 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:57 in forward, code: x = x.transpose(1, 2)  # (B, T, C) -> (B, C, T)
            transpose_9: "f32[512, 512, 7]" = torch.ops.aten.transpose.int(mul_3, 1, 2);  mul_3 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:59 in forward, code: x = residual + x
            add_3: "f32[512, 512, 7]" = torch.ops.aten.add.Tensor(add_2, transpose_9);  add_2 = transpose_9 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:375 in forward, code: return self._conv_forward(input, self.weight, self.bias)
            conv1d_5: "f32[512, 512, 7]" = torch.ops.aten.conv1d.default(add_3, p_backbone_convnext_4_dwconv_weight, p_backbone_convnext_4_dwconv_bias, [1], [3], [1], 512);  p_backbone_convnext_4_dwconv_weight = p_backbone_convnext_4_dwconv_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:46 in forward, code: x = x.transpose(1, 2)  # (B, C, T) -> (B, T, C)
            transpose_10: "f32[512, 7, 512]" = torch.ops.aten.transpose.int(conv1d_5, 1, 2);  conv1d_5 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
            layer_norm_5: "f32[512, 7, 512]" = torch.ops.aten.layer_norm.default(transpose_10, [512], p_backbone_convnext_4_norm_weight, p_backbone_convnext_4_norm_bias, 1e-06);  transpose_10 = p_backbone_convnext_4_norm_weight = p_backbone_convnext_4_norm_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
            linear_8: "f32[512, 7, 1536]" = torch.ops.aten.linear.default(layer_norm_5, p_backbone_convnext_4_pwconv1_weight, p_backbone_convnext_4_pwconv1_bias);  layer_norm_5 = p_backbone_convnext_4_pwconv1_weight = p_backbone_convnext_4_pwconv1_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:734 in forward, code: return F.gelu(input, approximate=self.approximate)
            gelu_4: "f32[512, 7, 1536]" = torch.ops.aten.gelu.default(linear_8);  linear_8 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
            linear_9: "f32[512, 7, 512]" = torch.ops.aten.linear.default(gelu_4, p_backbone_convnext_4_pwconv2_weight, p_backbone_convnext_4_pwconv2_bias);  gelu_4 = p_backbone_convnext_4_pwconv2_weight = p_backbone_convnext_4_pwconv2_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:56 in forward, code: x = self.gamma * x
            mul_4: "f32[512, 7, 512]" = torch.ops.aten.mul.Tensor(p_backbone_convnext_4_gamma, linear_9);  p_backbone_convnext_4_gamma = linear_9 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:57 in forward, code: x = x.transpose(1, 2)  # (B, T, C) -> (B, C, T)
            transpose_11: "f32[512, 512, 7]" = torch.ops.aten.transpose.int(mul_4, 1, 2);  mul_4 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:59 in forward, code: x = residual + x
            add_4: "f32[512, 512, 7]" = torch.ops.aten.add.Tensor(add_3, transpose_11);  add_3 = transpose_11 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:375 in forward, code: return self._conv_forward(input, self.weight, self.bias)
            conv1d_6: "f32[512, 512, 7]" = torch.ops.aten.conv1d.default(add_4, p_backbone_convnext_5_dwconv_weight, p_backbone_convnext_5_dwconv_bias, [1], [3], [1], 512);  p_backbone_convnext_5_dwconv_weight = p_backbone_convnext_5_dwconv_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:46 in forward, code: x = x.transpose(1, 2)  # (B, C, T) -> (B, T, C)
            transpose_12: "f32[512, 7, 512]" = torch.ops.aten.transpose.int(conv1d_6, 1, 2);  conv1d_6 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
            layer_norm_6: "f32[512, 7, 512]" = torch.ops.aten.layer_norm.default(transpose_12, [512], p_backbone_convnext_5_norm_weight, p_backbone_convnext_5_norm_bias, 1e-06);  transpose_12 = p_backbone_convnext_5_norm_weight = p_backbone_convnext_5_norm_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
            linear_10: "f32[512, 7, 1536]" = torch.ops.aten.linear.default(layer_norm_6, p_backbone_convnext_5_pwconv1_weight, p_backbone_convnext_5_pwconv1_bias);  layer_norm_6 = p_backbone_convnext_5_pwconv1_weight = p_backbone_convnext_5_pwconv1_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:734 in forward, code: return F.gelu(input, approximate=self.approximate)
            gelu_5: "f32[512, 7, 1536]" = torch.ops.aten.gelu.default(linear_10);  linear_10 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
            linear_11: "f32[512, 7, 512]" = torch.ops.aten.linear.default(gelu_5, p_backbone_convnext_5_pwconv2_weight, p_backbone_convnext_5_pwconv2_bias);  gelu_5 = p_backbone_convnext_5_pwconv2_weight = p_backbone_convnext_5_pwconv2_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:56 in forward, code: x = self.gamma * x
            mul_5: "f32[512, 7, 512]" = torch.ops.aten.mul.Tensor(p_backbone_convnext_5_gamma, linear_11);  p_backbone_convnext_5_gamma = linear_11 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:57 in forward, code: x = x.transpose(1, 2)  # (B, T, C) -> (B, C, T)
            transpose_13: "f32[512, 512, 7]" = torch.ops.aten.transpose.int(mul_5, 1, 2);  mul_5 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:59 in forward, code: x = residual + x
            add_5: "f32[512, 512, 7]" = torch.ops.aten.add.Tensor(add_4, transpose_13);  add_4 = transpose_13 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:375 in forward, code: return self._conv_forward(input, self.weight, self.bias)
            conv1d_7: "f32[512, 512, 7]" = torch.ops.aten.conv1d.default(add_5, p_backbone_convnext_6_dwconv_weight, p_backbone_convnext_6_dwconv_bias, [1], [3], [1], 512);  p_backbone_convnext_6_dwconv_weight = p_backbone_convnext_6_dwconv_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:46 in forward, code: x = x.transpose(1, 2)  # (B, C, T) -> (B, T, C)
            transpose_14: "f32[512, 7, 512]" = torch.ops.aten.transpose.int(conv1d_7, 1, 2);  conv1d_7 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
            layer_norm_7: "f32[512, 7, 512]" = torch.ops.aten.layer_norm.default(transpose_14, [512], p_backbone_convnext_6_norm_weight, p_backbone_convnext_6_norm_bias, 1e-06);  transpose_14 = p_backbone_convnext_6_norm_weight = p_backbone_convnext_6_norm_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
            linear_12: "f32[512, 7, 1536]" = torch.ops.aten.linear.default(layer_norm_7, p_backbone_convnext_6_pwconv1_weight, p_backbone_convnext_6_pwconv1_bias);  layer_norm_7 = p_backbone_convnext_6_pwconv1_weight = p_backbone_convnext_6_pwconv1_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:734 in forward, code: return F.gelu(input, approximate=self.approximate)
            gelu_6: "f32[512, 7, 1536]" = torch.ops.aten.gelu.default(linear_12);  linear_12 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
            linear_13: "f32[512, 7, 512]" = torch.ops.aten.linear.default(gelu_6, p_backbone_convnext_6_pwconv2_weight, p_backbone_convnext_6_pwconv2_bias);  gelu_6 = p_backbone_convnext_6_pwconv2_weight = p_backbone_convnext_6_pwconv2_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:56 in forward, code: x = self.gamma * x
            mul_6: "f32[512, 7, 512]" = torch.ops.aten.mul.Tensor(p_backbone_convnext_6_gamma, linear_13);  p_backbone_convnext_6_gamma = linear_13 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:57 in forward, code: x = x.transpose(1, 2)  # (B, T, C) -> (B, C, T)
            transpose_15: "f32[512, 512, 7]" = torch.ops.aten.transpose.int(mul_6, 1, 2);  mul_6 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:59 in forward, code: x = residual + x
            add_6: "f32[512, 512, 7]" = torch.ops.aten.add.Tensor(add_5, transpose_15);  add_5 = transpose_15 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:375 in forward, code: return self._conv_forward(input, self.weight, self.bias)
            conv1d_8: "f32[512, 512, 7]" = torch.ops.aten.conv1d.default(add_6, p_backbone_convnext_7_dwconv_weight, p_backbone_convnext_7_dwconv_bias, [1], [3], [1], 512);  p_backbone_convnext_7_dwconv_weight = p_backbone_convnext_7_dwconv_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:46 in forward, code: x = x.transpose(1, 2)  # (B, C, T) -> (B, T, C)
            transpose_16: "f32[512, 7, 512]" = torch.ops.aten.transpose.int(conv1d_8, 1, 2);  conv1d_8 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
            layer_norm_8: "f32[512, 7, 512]" = torch.ops.aten.layer_norm.default(transpose_16, [512], p_backbone_convnext_7_norm_weight, p_backbone_convnext_7_norm_bias, 1e-06);  transpose_16 = p_backbone_convnext_7_norm_weight = p_backbone_convnext_7_norm_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
            linear_14: "f32[512, 7, 1536]" = torch.ops.aten.linear.default(layer_norm_8, p_backbone_convnext_7_pwconv1_weight, p_backbone_convnext_7_pwconv1_bias);  layer_norm_8 = p_backbone_convnext_7_pwconv1_weight = p_backbone_convnext_7_pwconv1_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:734 in forward, code: return F.gelu(input, approximate=self.approximate)
            gelu_7: "f32[512, 7, 1536]" = torch.ops.aten.gelu.default(linear_14);  linear_14 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
            linear_15: "f32[512, 7, 512]" = torch.ops.aten.linear.default(gelu_7, p_backbone_convnext_7_pwconv2_weight, p_backbone_convnext_7_pwconv2_bias);  gelu_7 = p_backbone_convnext_7_pwconv2_weight = p_backbone_convnext_7_pwconv2_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:56 in forward, code: x = self.gamma * x
            mul_7: "f32[512, 7, 512]" = torch.ops.aten.mul.Tensor(p_backbone_convnext_7_gamma, linear_15);  p_backbone_convnext_7_gamma = linear_15 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:57 in forward, code: x = x.transpose(1, 2)  # (B, T, C) -> (B, C, T)
            transpose_17: "f32[512, 512, 7]" = torch.ops.aten.transpose.int(mul_7, 1, 2);  mul_7 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:59 in forward, code: x = residual + x
            add_7: "f32[512, 512, 7]" = torch.ops.aten.add.Tensor(add_6, transpose_17);  add_6 = transpose_17 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/models.py:88 in forward, code: x = self.final_layer_norm(x.transpose(1, 2))
            transpose_18: "f32[512, 7, 512]" = torch.ops.aten.transpose.int(add_7, 1, 2);  add_7 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:217 in forward, code: return F.layer_norm(
            layer_norm_9: "f32[512, 7, 512]" = torch.ops.aten.layer_norm.default(transpose_18, [512], p_backbone_final_layer_norm_weight, p_backbone_final_layer_norm_bias, 1e-06);  transpose_18 = p_backbone_final_layer_norm_weight = p_backbone_final_layer_norm_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
            linear_16: "f32[512, 7, 1026]" = torch.ops.aten.linear.default(layer_norm_9, p_head_out_weight, p_head_out_bias);  layer_norm_9 = p_head_out_weight = p_head_out_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/heads.py:55 in forward, code: x = self.out(x).transpose(1, 2)
            transpose_19: "f32[512, 1026, 7]" = torch.ops.aten.transpose.int(linear_16, 1, 2);  linear_16 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/heads.py:56 in forward, code: mag, p = x.chunk(2, dim=1)
            split = torch.ops.aten.split.Tensor(transpose_19, 513, 1);  transpose_19 = None
            getitem: "f32[512, 513, 7]" = split[0]
            getitem_1: "f32[512, 513, 7]" = split[1];  split = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/heads.py:57 in forward, code: mag = torch.exp(mag)
            exp: "f32[512, 513, 7]" = torch.ops.aten.exp.default(getitem);  getitem = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/heads.py:58 in forward, code: mag = torch.clip(mag, max=1e2)  # safeguard to prevent excessively large magnitudes
            clip: "f32[512, 513, 7]" = torch.ops.aten.clip.default(exp, None, 100.0);  exp = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/heads.py:60 in forward, code: x = torch.cos(p)
            cos: "f32[512, 513, 7]" = torch.ops.aten.cos.default(getitem_1)
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/heads.py:61 in forward, code: y = torch.sin(p)
            sin: "f32[512, 513, 7]" = torch.ops.aten.sin.default(getitem_1);  getitem_1 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/heads.py:67 in forward, code: S = mag * (x + 1j * y)
            mul_8: "c64[512, 513, 7]" = torch.ops.aten.mul.Tensor(sin, 1j);  sin = None
            add_8: "c64[512, 513, 7]" = torch.ops.aten.add.Tensor(cos, mul_8);  cos = mul_8 = None
            mul_9: "c64[512, 513, 7]" = torch.ops.aten.mul.Tensor(clip, add_8);  clip = add_8 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/spectral_ops.py:46 in forward, code: return torch.istft(spec, self.n_fft, self.hop_length, self.win_length, self.window, center=True)
            istft: "f32[512, 1536]" = torch.ops.aten.istft.default(mul_9, 1024, 256, 1024, b_head_istft_window);  mul_9 = b_head_istft_window = None
            return (istft,)
            
Graph signature: ExportGraphSignature(input_specs=[InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_embed_weight'), target='backbone.embed.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_embed_bias'), target='backbone.embed.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_norm_weight'), target='backbone.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_norm_bias'), target='backbone.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_0_gamma'), target='backbone.convnext.0.gamma', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_0_dwconv_weight'), target='backbone.convnext.0.dwconv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_0_dwconv_bias'), target='backbone.convnext.0.dwconv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_0_norm_weight'), target='backbone.convnext.0.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_0_norm_bias'), target='backbone.convnext.0.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_0_pwconv1_weight'), target='backbone.convnext.0.pwconv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_0_pwconv1_bias'), target='backbone.convnext.0.pwconv1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_0_pwconv2_weight'), target='backbone.convnext.0.pwconv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_0_pwconv2_bias'), target='backbone.convnext.0.pwconv2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_1_gamma'), target='backbone.convnext.1.gamma', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_1_dwconv_weight'), target='backbone.convnext.1.dwconv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_1_dwconv_bias'), target='backbone.convnext.1.dwconv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_1_norm_weight'), target='backbone.convnext.1.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_1_norm_bias'), target='backbone.convnext.1.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_1_pwconv1_weight'), target='backbone.convnext.1.pwconv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_1_pwconv1_bias'), target='backbone.convnext.1.pwconv1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_1_pwconv2_weight'), target='backbone.convnext.1.pwconv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_1_pwconv2_bias'), target='backbone.convnext.1.pwconv2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_2_gamma'), target='backbone.convnext.2.gamma', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_2_dwconv_weight'), target='backbone.convnext.2.dwconv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_2_dwconv_bias'), target='backbone.convnext.2.dwconv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_2_norm_weight'), target='backbone.convnext.2.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_2_norm_bias'), target='backbone.convnext.2.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_2_pwconv1_weight'), target='backbone.convnext.2.pwconv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_2_pwconv1_bias'), target='backbone.convnext.2.pwconv1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_2_pwconv2_weight'), target='backbone.convnext.2.pwconv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_2_pwconv2_bias'), target='backbone.convnext.2.pwconv2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_3_gamma'), target='backbone.convnext.3.gamma', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_3_dwconv_weight'), target='backbone.convnext.3.dwconv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_3_dwconv_bias'), target='backbone.convnext.3.dwconv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_3_norm_weight'), target='backbone.convnext.3.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_3_norm_bias'), target='backbone.convnext.3.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_3_pwconv1_weight'), target='backbone.convnext.3.pwconv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_3_pwconv1_bias'), target='backbone.convnext.3.pwconv1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_3_pwconv2_weight'), target='backbone.convnext.3.pwconv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_3_pwconv2_bias'), target='backbone.convnext.3.pwconv2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_4_gamma'), target='backbone.convnext.4.gamma', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_4_dwconv_weight'), target='backbone.convnext.4.dwconv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_4_dwconv_bias'), target='backbone.convnext.4.dwconv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_4_norm_weight'), target='backbone.convnext.4.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_4_norm_bias'), target='backbone.convnext.4.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_4_pwconv1_weight'), target='backbone.convnext.4.pwconv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_4_pwconv1_bias'), target='backbone.convnext.4.pwconv1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_4_pwconv2_weight'), target='backbone.convnext.4.pwconv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_4_pwconv2_bias'), target='backbone.convnext.4.pwconv2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_5_gamma'), target='backbone.convnext.5.gamma', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_5_dwconv_weight'), target='backbone.convnext.5.dwconv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_5_dwconv_bias'), target='backbone.convnext.5.dwconv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_5_norm_weight'), target='backbone.convnext.5.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_5_norm_bias'), target='backbone.convnext.5.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_5_pwconv1_weight'), target='backbone.convnext.5.pwconv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_5_pwconv1_bias'), target='backbone.convnext.5.pwconv1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_5_pwconv2_weight'), target='backbone.convnext.5.pwconv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_5_pwconv2_bias'), target='backbone.convnext.5.pwconv2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_6_gamma'), target='backbone.convnext.6.gamma', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_6_dwconv_weight'), target='backbone.convnext.6.dwconv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_6_dwconv_bias'), target='backbone.convnext.6.dwconv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_6_norm_weight'), target='backbone.convnext.6.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_6_norm_bias'), target='backbone.convnext.6.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_6_pwconv1_weight'), target='backbone.convnext.6.pwconv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_6_pwconv1_bias'), target='backbone.convnext.6.pwconv1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_6_pwconv2_weight'), target='backbone.convnext.6.pwconv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_6_pwconv2_bias'), target='backbone.convnext.6.pwconv2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_7_gamma'), target='backbone.convnext.7.gamma', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_7_dwconv_weight'), target='backbone.convnext.7.dwconv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_7_dwconv_bias'), target='backbone.convnext.7.dwconv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_7_norm_weight'), target='backbone.convnext.7.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_7_norm_bias'), target='backbone.convnext.7.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_7_pwconv1_weight'), target='backbone.convnext.7.pwconv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_7_pwconv1_bias'), target='backbone.convnext.7.pwconv1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_7_pwconv2_weight'), target='backbone.convnext.7.pwconv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_convnext_7_pwconv2_bias'), target='backbone.convnext.7.pwconv2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_final_layer_norm_weight'), target='backbone.final_layer_norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_backbone_final_layer_norm_bias'), target='backbone.final_layer_norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_head_out_weight'), target='head.out.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_head_out_bias'), target='head.out.bias', persistent=None), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_feature_extractor_mel_spec_spectrogram_window'), target='feature_extractor.mel_spec.spectrogram.window', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_feature_extractor_mel_spec_mel_scale_fb'), target='feature_extractor.mel_spec.mel_scale.fb', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_head_istft_window'), target='head.istft.window', persistent=True), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='x'), target=None, persistent=None)], output_specs=[OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='istft'), target=None)])
Range constraints: {}

```

## Analysis

PyTorch ONNX Conversion Analysis

## Model Information

The model has 13531650 parameters and 53348 buffers (non-trainable parameters).
Number of parameters per dtype:
```python
defaultdict(<class 'int'>, {torch.float32: 13531650})
```
Number of buffers per dtype:
```python
defaultdict(<class 'int'>, {torch.float32: 53348})
```

Inputs:
- `x`: `TensorMetadata(shape=torch.Size([512, 100, 7]), dtype=torch.float32, requires_grad=False, stride=(700, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})`

Outputs:
- `istft`: `TensorMetadata(shape=torch.Size([512, 1536]), dtype=torch.float32, requires_grad=False, stride=(1536, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})`

The FX graph has 176 nodes in total. Number of FX nodes per op:
- `placeholder`: 84
- `call_function`: 91
- `output`: 1


Of the call_function nodes, the counts of operators used are:

- `aten.transpose.int`: 20
- `aten.linear.default`: 17
- `aten.layer_norm.default`: 10
- `aten.mul.Tensor`: 10
- `aten.conv1d.default`: 9
- `aten.add.Tensor`: 9
- `aten.gelu.default`: 8
- `<built-in function getitem>`: 2
- `aten.split.Tensor`: 1
- `aten.exp.default`: 1
- `aten.clip.default`: 1
- `aten.cos.default`: 1
- `aten.sin.default`: 1
- `aten.istft.default`: 1

## ONNX Conversion Information

The model contains operators the dispatcher could not find registered ONNX decompositions for. This may be due to missing implementations, decompositions not registered correctly, or a bug in the dispatcher.

Errors grouped by operator:

- `aten.linear.default`:     No decompositions registered for the real-valued input. Example node: `%linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%layer_norm_1, %p_backbone_convnext_0_pwconv1_weight, %p_backbone_convnext_0_pwconv1_bias), kwargs = {})`. All nodes: `[linear, linear_1, linear_2, linear_3, linear_4, linear_5, linear_6, linear_7, linear_8, linear_9, linear_10, linear_11, linear_12, linear_13, linear_14, linear_15, linear_16]`
- `aten.istft.default`:     No decompositions registered for the complex-valued input. Example node: `%istft : [num_users=1] = call_function[target=torch.ops.aten.istft.default](args = (%mul_9, 1024, 256, 1024, %b_head_istft_window), kwargs = {})`. All nodes: `[istft]`
- `aten.clip.default`:     No decompositions registered for the real-valued input. Example node: `%clip : [num_users=1] = call_function[target=torch.ops.aten.clip.default](args = (%exp, None, 100.0), kwargs = {})`. All nodes: `[clip]`

## Decomposition comparison

Ops exist only in the ExportedProgram before decomposition: `['aten.clip.default', 'aten.istft.default', 'aten.linear.default']`

Ops exist only in the ExportedProgram after decomposition: `['aten._unsafe_index_put.default', 'aten._unsafe_view.default', 'aten.addmm.default', 'aten.arange.default', 'aten.clamp.default', 'aten.clone.default', 'aten.div.Tensor', 'aten.expand.default', 'aten.new_zeros.default', 'aten.permute.default', 'aten.pow.Tensor_Tensor', 'aten.scalar_tensor.default', 'aten.slice.Tensor', 'aten.t.default', 'aten.unfold.default', 'aten.view.default', 'prims.convert_element_type.default', 'prims.fft_c2r.default']`

