# PyTorch ONNX Conversion Report

```
✅ Obtain model graph with `torch.export.export`
⚪ Obtain model graph with `torch.export.export(..., strict=False)`
⚪ Obtain model graph with `torch.jit.trace`
❌ Translate the graph into ONNX
⚪ Run `onnx.checker` on the ONNX model
⚪ Execute the model with ONNX Runtime
⚪ Validate model output accuracy
```

## Error messages

```pytb


Traceback (most recent call last):

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_building.py", line 516, in _call_op
    converted_named_inputs = _process_python_constants(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_building.py", line 335, in _process_python_constants
    dtype = _determine_input_dtype(param, arg, type_binding)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_building.py", line 231, in _determine_input_dtype
    raise ValueError(

ValueError: Could not determine the dtype for the input 'data'. param=data: T, arg=1j, param_type_constraint=T=COMPLEX64 | FLOAT | INT16 | INT8 | UINT16 | UINT32 | FLOAT16 | BOOL | INT32 | DOUBLE | STRING | COMPLEX128 | UINT8 | INT64 | UINT64 | BFLOAT16, type_binding={}


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_building.py", line 579, in eval
    outputs = self._call_op(op_signature, named_inputs, named_attrs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_building.py", line 528, in _call_op
    raise _errors.GraphConstructionError(

torch.onnx._internal.exporter._errors.GraphConstructionError: Error processing Python constants for operator '::Slice'. named_inputs={'data': 1j, 'starts': [0], 'ends': [1], 'axes': [-1], 'steps': None}, named_attrs={}, opset=, op_signature=''::Slice(data: T, starts: Tind, ends: Tind, axes: Tind, steps: Tind) -> (T) where T=COMPLEX64 | FLOAT | INT16 | INT8 | UINT16 | UINT32 | FLOAT16 | BOOL | INT32 | DOUBLE | STRING | COMPLEX128 | UINT8 | INT64 | UINT64 | BFLOAT16, Tind=INT32 | INT64.


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_building.py", line 655, in eval_function
    return function.function(**named_inputs, **named_attrs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/onnxscript/function_libs/torch_lib/ops/core.py", line 5617, in aten_mul_complex
    other_real = op.Slice(other, [0], [1], axes=[-1])
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/onnxscript/onnx_opset/_impl/opset13.py", line 3460, in Slice
    return op(*self._prepare_inputs(schema, data, starts, ends, axes, steps))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/onnxscript/values.py", line 301, in __call__
    return evaluator.default().eval(schema, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_building.py", line 584, in eval
    raise _errors.GraphConstructionError(

torch.onnx._internal.exporter._errors.GraphConstructionError: Error calling operator 'Slice' with args (1j, [0], [1], [-1]) and kwargs {}.


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py", line 469, in _handle_call_function_node_with_lowering
    outputs = onnx_function(*onnx_args, **onnx_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/onnxscript/values.py", line 529, in __call__
    return evaluator.default().eval_function(self, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_building.py", line 669, in eval_function
    raise _errors.GraphConstructionError(

torch.onnx._internal.exporter._errors.GraphConstructionError: Error calling function 'aten_mul_complex' with args (SymbolicTensor('convert_element_type_default', type=Tensor(FLOAT), shape=[512,513,7,2], producer=node_Concat_188, index=0), 1j) and kwargs {}. The function is defined at '/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/onnxscript/function_libs/torch_lib/ops/core.py:5606'.


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py", line 553, in _add_nodes
    _handle_call_function_node_with_lowering(

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py", line 471, in _handle_call_function_node_with_lowering
    raise _errors.GraphConstructionError(

torch.onnx._internal.exporter._errors.GraphConstructionError: Error when calling function 'OnnxFunction(<function aten_mul_complex at 0x7cd85a1b67a0>)' with args '[SymbolicTensor('convert_element_type_default', type=Tensor(FLOAT), shape=[512,513,7,2], producer=node_Concat_188, index=0), 1j]' and kwargs '{}'


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py", line 1141, in export
    onnx_program = _exported_program_to_onnx_program(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py", line 798, in _exported_program_to_onnx_program
    values = _add_nodes(exported_program, model, lower=lower, registry=registry)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter/_core.py", line 565, in _add_nodes
    raise _errors.ConversionError(

torch.onnx._internal.exporter._errors.ConversionError: Error when translating node %mul_8 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_default, 1j), kwargs = {}). See the stack trace for more information.

```

## Exported program

```python
ExportedProgram:
    class GraphModule(torch.nn.Module):
        def forward(self, p_l__vocos____modules__backbone___convnext_0_gamma: "f32[512]", p_l__vocos____modules__backbone___convnext_1_gamma: "f32[512]", p_l__vocos____modules__backbone___convnext_2_gamma: "f32[512]", p_l__vocos____modules__backbone___convnext_3_gamma: "f32[512]", p_l__vocos____modules__backbone___convnext_4_gamma: "f32[512]", p_l__vocos____modules__backbone___convnext_5_gamma: "f32[512]", p_l__vocos____modules__backbone___convnext_6_gamma: "f32[512]", p_l__vocos____modules__backbone___convnext_7_gamma: "f32[512]", p_l__vocos____modules__backbone___embed_weight: "f32[512, 100, 7]", p_l__vocos____modules__backbone___embed_bias: "f32[512]", p_l__vocos____modules__backbone___norm_weight: "f32[512]", p_l__vocos____modules__backbone___norm_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_0_dwconv_weight: "f32[512, 1, 7]", p_l__vocos____modules__backbone___convnext_0_dwconv_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_0_norm_weight: "f32[512]", p_l__vocos____modules__backbone___convnext_0_norm_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_0_pwconv1_weight: "f32[1536, 512]", p_l__vocos____modules__backbone___convnext_0_pwconv1_bias: "f32[1536]", p_l__vocos____modules__backbone___convnext_0_pwconv2_weight: "f32[512, 1536]", p_l__vocos____modules__backbone___convnext_0_pwconv2_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_1_dwconv_weight: "f32[512, 1, 7]", p_l__vocos____modules__backbone___convnext_1_dwconv_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_1_norm_weight: "f32[512]", p_l__vocos____modules__backbone___convnext_1_norm_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_1_pwconv1_weight: "f32[1536, 512]", p_l__vocos____modules__backbone___convnext_1_pwconv1_bias: "f32[1536]", p_l__vocos____modules__backbone___convnext_1_pwconv2_weight: "f32[512, 1536]", p_l__vocos____modules__backbone___convnext_1_pwconv2_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_2_dwconv_weight: "f32[512, 1, 7]", p_l__vocos____modules__backbone___convnext_2_dwconv_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_2_norm_weight: "f32[512]", p_l__vocos____modules__backbone___convnext_2_norm_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_2_pwconv1_weight: "f32[1536, 512]", p_l__vocos____modules__backbone___convnext_2_pwconv1_bias: "f32[1536]", p_l__vocos____modules__backbone___convnext_2_pwconv2_weight: "f32[512, 1536]", p_l__vocos____modules__backbone___convnext_2_pwconv2_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_3_dwconv_weight: "f32[512, 1, 7]", p_l__vocos____modules__backbone___convnext_3_dwconv_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_3_norm_weight: "f32[512]", p_l__vocos____modules__backbone___convnext_3_norm_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_3_pwconv1_weight: "f32[1536, 512]", p_l__vocos____modules__backbone___convnext_3_pwconv1_bias: "f32[1536]", p_l__vocos____modules__backbone___convnext_3_pwconv2_weight: "f32[512, 1536]", p_l__vocos____modules__backbone___convnext_3_pwconv2_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_4_dwconv_weight: "f32[512, 1, 7]", p_l__vocos____modules__backbone___convnext_4_dwconv_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_4_norm_weight: "f32[512]", p_l__vocos____modules__backbone___convnext_4_norm_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_4_pwconv1_weight: "f32[1536, 512]", p_l__vocos____modules__backbone___convnext_4_pwconv1_bias: "f32[1536]", p_l__vocos____modules__backbone___convnext_4_pwconv2_weight: "f32[512, 1536]", p_l__vocos____modules__backbone___convnext_4_pwconv2_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_5_dwconv_weight: "f32[512, 1, 7]", p_l__vocos____modules__backbone___convnext_5_dwconv_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_5_norm_weight: "f32[512]", p_l__vocos____modules__backbone___convnext_5_norm_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_5_pwconv1_weight: "f32[1536, 512]", p_l__vocos____modules__backbone___convnext_5_pwconv1_bias: "f32[1536]", p_l__vocos____modules__backbone___convnext_5_pwconv2_weight: "f32[512, 1536]", p_l__vocos____modules__backbone___convnext_5_pwconv2_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_6_dwconv_weight: "f32[512, 1, 7]", p_l__vocos____modules__backbone___convnext_6_dwconv_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_6_norm_weight: "f32[512]", p_l__vocos____modules__backbone___convnext_6_norm_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_6_pwconv1_weight: "f32[1536, 512]", p_l__vocos____modules__backbone___convnext_6_pwconv1_bias: "f32[1536]", p_l__vocos____modules__backbone___convnext_6_pwconv2_weight: "f32[512, 1536]", p_l__vocos____modules__backbone___convnext_6_pwconv2_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_7_dwconv_weight: "f32[512, 1, 7]", p_l__vocos____modules__backbone___convnext_7_dwconv_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_7_norm_weight: "f32[512]", p_l__vocos____modules__backbone___convnext_7_norm_bias: "f32[512]", p_l__vocos____modules__backbone___convnext_7_pwconv1_weight: "f32[1536, 512]", p_l__vocos____modules__backbone___convnext_7_pwconv1_bias: "f32[1536]", p_l__vocos____modules__backbone___convnext_7_pwconv2_weight: "f32[512, 1536]", p_l__vocos____modules__backbone___convnext_7_pwconv2_bias: "f32[512]", p_l__vocos____modules__backbone___final_layer_norm_weight: "f32[512]", p_l__vocos____modules__backbone___final_layer_norm_bias: "f32[512]", p_l__vocos____modules__head___out_weight: "f32[1026, 512]", p_l__vocos____modules__head___out_bias: "f32[1026]", b_l__vocos____modules__head___istft_window: "f32[1024]", x: "f32[512, 100, 7]"):
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/models.py:79 in forward, code: x = self.embed(x)
            conv1d: "f32[512, 512, 7]" = torch.ops.aten.conv1d.default(x, p_l__vocos____modules__backbone___embed_weight, p_l__vocos____modules__backbone___embed_bias, [1], [3]);  x = p_l__vocos____modules__backbone___embed_weight = p_l__vocos____modules__backbone___embed_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/models.py:84 in forward, code: x = self.norm(x.transpose(1, 2))
            transpose: "f32[512, 7, 512]" = torch.ops.aten.transpose.int(conv1d, 1, 2);  conv1d = None
            layer_norm: "f32[512, 7, 512]" = torch.ops.aten.layer_norm.default(transpose, [512], p_l__vocos____modules__backbone___norm_weight, p_l__vocos____modules__backbone___norm_bias, 1e-06);  transpose = p_l__vocos____modules__backbone___norm_weight = p_l__vocos____modules__backbone___norm_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/models.py:85 in forward, code: x = x.transpose(1, 2)
            transpose_1: "f32[512, 512, 7]" = torch.ops.aten.transpose.int(layer_norm, 1, 2);  layer_norm = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:45 in forward, code: x = self.dwconv(x)
            conv1d_1: "f32[512, 512, 7]" = torch.ops.aten.conv1d.default(transpose_1, p_l__vocos____modules__backbone___convnext_0_dwconv_weight, p_l__vocos____modules__backbone___convnext_0_dwconv_bias, [1], [3], [1], 512);  p_l__vocos____modules__backbone___convnext_0_dwconv_weight = p_l__vocos____modules__backbone___convnext_0_dwconv_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:46 in forward, code: x = x.transpose(1, 2)  # (B, C, T) -> (B, T, C)
            transpose_2: "f32[512, 7, 512]" = torch.ops.aten.transpose.int(conv1d_1, 1, 2);  conv1d_1 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:51 in forward, code: x = self.norm(x)
            layer_norm_1: "f32[512, 7, 512]" = torch.ops.aten.layer_norm.default(transpose_2, [512], p_l__vocos____modules__backbone___convnext_0_norm_weight, p_l__vocos____modules__backbone___convnext_0_norm_bias, 1e-06);  transpose_2 = p_l__vocos____modules__backbone___convnext_0_norm_weight = p_l__vocos____modules__backbone___convnext_0_norm_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:52 in forward, code: x = self.pwconv1(x)
            linear: "f32[512, 7, 1536]" = torch.ops.aten.linear.default(layer_norm_1, p_l__vocos____modules__backbone___convnext_0_pwconv1_weight, p_l__vocos____modules__backbone___convnext_0_pwconv1_bias);  layer_norm_1 = p_l__vocos____modules__backbone___convnext_0_pwconv1_weight = p_l__vocos____modules__backbone___convnext_0_pwconv1_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:53 in forward, code: x = self.act(x)
            gelu: "f32[512, 7, 1536]" = torch.ops.aten.gelu.default(linear);  linear = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:54 in forward, code: x = self.pwconv2(x)
            linear_1: "f32[512, 7, 512]" = torch.ops.aten.linear.default(gelu, p_l__vocos____modules__backbone___convnext_0_pwconv2_weight, p_l__vocos____modules__backbone___convnext_0_pwconv2_bias);  gelu = p_l__vocos____modules__backbone___convnext_0_pwconv2_weight = p_l__vocos____modules__backbone___convnext_0_pwconv2_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:56 in forward, code: x = self.gamma * x
            mul: "f32[512, 7, 512]" = torch.ops.aten.mul.Tensor(p_l__vocos____modules__backbone___convnext_0_gamma, linear_1);  p_l__vocos____modules__backbone___convnext_0_gamma = linear_1 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:57 in forward, code: x = x.transpose(1, 2)  # (B, T, C) -> (B, C, T)
            transpose_3: "f32[512, 512, 7]" = torch.ops.aten.transpose.int(mul, 1, 2);  mul = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:59 in forward, code: x = residual + x
            add: "f32[512, 512, 7]" = torch.ops.aten.add.Tensor(transpose_1, transpose_3);  transpose_1 = transpose_3 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:45 in forward, code: x = self.dwconv(x)
            conv1d_2: "f32[512, 512, 7]" = torch.ops.aten.conv1d.default(add, p_l__vocos____modules__backbone___convnext_1_dwconv_weight, p_l__vocos____modules__backbone___convnext_1_dwconv_bias, [1], [3], [1], 512);  p_l__vocos____modules__backbone___convnext_1_dwconv_weight = p_l__vocos____modules__backbone___convnext_1_dwconv_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:46 in forward, code: x = x.transpose(1, 2)  # (B, C, T) -> (B, T, C)
            transpose_4: "f32[512, 7, 512]" = torch.ops.aten.transpose.int(conv1d_2, 1, 2);  conv1d_2 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:51 in forward, code: x = self.norm(x)
            layer_norm_2: "f32[512, 7, 512]" = torch.ops.aten.layer_norm.default(transpose_4, [512], p_l__vocos____modules__backbone___convnext_1_norm_weight, p_l__vocos____modules__backbone___convnext_1_norm_bias, 1e-06);  transpose_4 = p_l__vocos____modules__backbone___convnext_1_norm_weight = p_l__vocos____modules__backbone___convnext_1_norm_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:52 in forward, code: x = self.pwconv1(x)
            linear_2: "f32[512, 7, 1536]" = torch.ops.aten.linear.default(layer_norm_2, p_l__vocos____modules__backbone___convnext_1_pwconv1_weight, p_l__vocos____modules__backbone___convnext_1_pwconv1_bias);  layer_norm_2 = p_l__vocos____modules__backbone___convnext_1_pwconv1_weight = p_l__vocos____modules__backbone___convnext_1_pwconv1_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:53 in forward, code: x = self.act(x)
            gelu_1: "f32[512, 7, 1536]" = torch.ops.aten.gelu.default(linear_2);  linear_2 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:54 in forward, code: x = self.pwconv2(x)
            linear_3: "f32[512, 7, 512]" = torch.ops.aten.linear.default(gelu_1, p_l__vocos____modules__backbone___convnext_1_pwconv2_weight, p_l__vocos____modules__backbone___convnext_1_pwconv2_bias);  gelu_1 = p_l__vocos____modules__backbone___convnext_1_pwconv2_weight = p_l__vocos____modules__backbone___convnext_1_pwconv2_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:56 in forward, code: x = self.gamma * x
            mul_1: "f32[512, 7, 512]" = torch.ops.aten.mul.Tensor(p_l__vocos____modules__backbone___convnext_1_gamma, linear_3);  p_l__vocos____modules__backbone___convnext_1_gamma = linear_3 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:57 in forward, code: x = x.transpose(1, 2)  # (B, T, C) -> (B, C, T)
            transpose_5: "f32[512, 512, 7]" = torch.ops.aten.transpose.int(mul_1, 1, 2);  mul_1 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:59 in forward, code: x = residual + x
            add_1: "f32[512, 512, 7]" = torch.ops.aten.add.Tensor(add, transpose_5);  add = transpose_5 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:45 in forward, code: x = self.dwconv(x)
            conv1d_3: "f32[512, 512, 7]" = torch.ops.aten.conv1d.default(add_1, p_l__vocos____modules__backbone___convnext_2_dwconv_weight, p_l__vocos____modules__backbone___convnext_2_dwconv_bias, [1], [3], [1], 512);  p_l__vocos____modules__backbone___convnext_2_dwconv_weight = p_l__vocos____modules__backbone___convnext_2_dwconv_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:46 in forward, code: x = x.transpose(1, 2)  # (B, C, T) -> (B, T, C)
            transpose_6: "f32[512, 7, 512]" = torch.ops.aten.transpose.int(conv1d_3, 1, 2);  conv1d_3 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:51 in forward, code: x = self.norm(x)
            layer_norm_3: "f32[512, 7, 512]" = torch.ops.aten.layer_norm.default(transpose_6, [512], p_l__vocos____modules__backbone___convnext_2_norm_weight, p_l__vocos____modules__backbone___convnext_2_norm_bias, 1e-06);  transpose_6 = p_l__vocos____modules__backbone___convnext_2_norm_weight = p_l__vocos____modules__backbone___convnext_2_norm_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:52 in forward, code: x = self.pwconv1(x)
            linear_4: "f32[512, 7, 1536]" = torch.ops.aten.linear.default(layer_norm_3, p_l__vocos____modules__backbone___convnext_2_pwconv1_weight, p_l__vocos____modules__backbone___convnext_2_pwconv1_bias);  layer_norm_3 = p_l__vocos____modules__backbone___convnext_2_pwconv1_weight = p_l__vocos____modules__backbone___convnext_2_pwconv1_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:53 in forward, code: x = self.act(x)
            gelu_2: "f32[512, 7, 1536]" = torch.ops.aten.gelu.default(linear_4);  linear_4 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:54 in forward, code: x = self.pwconv2(x)
            linear_5: "f32[512, 7, 512]" = torch.ops.aten.linear.default(gelu_2, p_l__vocos____modules__backbone___convnext_2_pwconv2_weight, p_l__vocos____modules__backbone___convnext_2_pwconv2_bias);  gelu_2 = p_l__vocos____modules__backbone___convnext_2_pwconv2_weight = p_l__vocos____modules__backbone___convnext_2_pwconv2_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:56 in forward, code: x = self.gamma * x
            mul_2: "f32[512, 7, 512]" = torch.ops.aten.mul.Tensor(p_l__vocos____modules__backbone___convnext_2_gamma, linear_5);  p_l__vocos____modules__backbone___convnext_2_gamma = linear_5 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:57 in forward, code: x = x.transpose(1, 2)  # (B, T, C) -> (B, C, T)
            transpose_7: "f32[512, 512, 7]" = torch.ops.aten.transpose.int(mul_2, 1, 2);  mul_2 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:59 in forward, code: x = residual + x
            add_2: "f32[512, 512, 7]" = torch.ops.aten.add.Tensor(add_1, transpose_7);  add_1 = transpose_7 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:45 in forward, code: x = self.dwconv(x)
            conv1d_4: "f32[512, 512, 7]" = torch.ops.aten.conv1d.default(add_2, p_l__vocos____modules__backbone___convnext_3_dwconv_weight, p_l__vocos____modules__backbone___convnext_3_dwconv_bias, [1], [3], [1], 512);  p_l__vocos____modules__backbone___convnext_3_dwconv_weight = p_l__vocos____modules__backbone___convnext_3_dwconv_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:46 in forward, code: x = x.transpose(1, 2)  # (B, C, T) -> (B, T, C)
            transpose_8: "f32[512, 7, 512]" = torch.ops.aten.transpose.int(conv1d_4, 1, 2);  conv1d_4 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:51 in forward, code: x = self.norm(x)
            layer_norm_4: "f32[512, 7, 512]" = torch.ops.aten.layer_norm.default(transpose_8, [512], p_l__vocos____modules__backbone___convnext_3_norm_weight, p_l__vocos____modules__backbone___convnext_3_norm_bias, 1e-06);  transpose_8 = p_l__vocos____modules__backbone___convnext_3_norm_weight = p_l__vocos____modules__backbone___convnext_3_norm_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:52 in forward, code: x = self.pwconv1(x)
            linear_6: "f32[512, 7, 1536]" = torch.ops.aten.linear.default(layer_norm_4, p_l__vocos____modules__backbone___convnext_3_pwconv1_weight, p_l__vocos____modules__backbone___convnext_3_pwconv1_bias);  layer_norm_4 = p_l__vocos____modules__backbone___convnext_3_pwconv1_weight = p_l__vocos____modules__backbone___convnext_3_pwconv1_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:53 in forward, code: x = self.act(x)
            gelu_3: "f32[512, 7, 1536]" = torch.ops.aten.gelu.default(linear_6);  linear_6 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:54 in forward, code: x = self.pwconv2(x)
            linear_7: "f32[512, 7, 512]" = torch.ops.aten.linear.default(gelu_3, p_l__vocos____modules__backbone___convnext_3_pwconv2_weight, p_l__vocos____modules__backbone___convnext_3_pwconv2_bias);  gelu_3 = p_l__vocos____modules__backbone___convnext_3_pwconv2_weight = p_l__vocos____modules__backbone___convnext_3_pwconv2_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:56 in forward, code: x = self.gamma * x
            mul_3: "f32[512, 7, 512]" = torch.ops.aten.mul.Tensor(p_l__vocos____modules__backbone___convnext_3_gamma, linear_7);  p_l__vocos____modules__backbone___convnext_3_gamma = linear_7 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:57 in forward, code: x = x.transpose(1, 2)  # (B, T, C) -> (B, C, T)
            transpose_9: "f32[512, 512, 7]" = torch.ops.aten.transpose.int(mul_3, 1, 2);  mul_3 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:59 in forward, code: x = residual + x
            add_3: "f32[512, 512, 7]" = torch.ops.aten.add.Tensor(add_2, transpose_9);  add_2 = transpose_9 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:45 in forward, code: x = self.dwconv(x)
            conv1d_5: "f32[512, 512, 7]" = torch.ops.aten.conv1d.default(add_3, p_l__vocos____modules__backbone___convnext_4_dwconv_weight, p_l__vocos____modules__backbone___convnext_4_dwconv_bias, [1], [3], [1], 512);  p_l__vocos____modules__backbone___convnext_4_dwconv_weight = p_l__vocos____modules__backbone___convnext_4_dwconv_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:46 in forward, code: x = x.transpose(1, 2)  # (B, C, T) -> (B, T, C)
            transpose_10: "f32[512, 7, 512]" = torch.ops.aten.transpose.int(conv1d_5, 1, 2);  conv1d_5 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:51 in forward, code: x = self.norm(x)
            layer_norm_5: "f32[512, 7, 512]" = torch.ops.aten.layer_norm.default(transpose_10, [512], p_l__vocos____modules__backbone___convnext_4_norm_weight, p_l__vocos____modules__backbone___convnext_4_norm_bias, 1e-06);  transpose_10 = p_l__vocos____modules__backbone___convnext_4_norm_weight = p_l__vocos____modules__backbone___convnext_4_norm_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:52 in forward, code: x = self.pwconv1(x)
            linear_8: "f32[512, 7, 1536]" = torch.ops.aten.linear.default(layer_norm_5, p_l__vocos____modules__backbone___convnext_4_pwconv1_weight, p_l__vocos____modules__backbone___convnext_4_pwconv1_bias);  layer_norm_5 = p_l__vocos____modules__backbone___convnext_4_pwconv1_weight = p_l__vocos____modules__backbone___convnext_4_pwconv1_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:53 in forward, code: x = self.act(x)
            gelu_4: "f32[512, 7, 1536]" = torch.ops.aten.gelu.default(linear_8);  linear_8 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:54 in forward, code: x = self.pwconv2(x)
            linear_9: "f32[512, 7, 512]" = torch.ops.aten.linear.default(gelu_4, p_l__vocos____modules__backbone___convnext_4_pwconv2_weight, p_l__vocos____modules__backbone___convnext_4_pwconv2_bias);  gelu_4 = p_l__vocos____modules__backbone___convnext_4_pwconv2_weight = p_l__vocos____modules__backbone___convnext_4_pwconv2_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:56 in forward, code: x = self.gamma * x
            mul_4: "f32[512, 7, 512]" = torch.ops.aten.mul.Tensor(p_l__vocos____modules__backbone___convnext_4_gamma, linear_9);  p_l__vocos____modules__backbone___convnext_4_gamma = linear_9 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:57 in forward, code: x = x.transpose(1, 2)  # (B, T, C) -> (B, C, T)
            transpose_11: "f32[512, 512, 7]" = torch.ops.aten.transpose.int(mul_4, 1, 2);  mul_4 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:59 in forward, code: x = residual + x
            add_4: "f32[512, 512, 7]" = torch.ops.aten.add.Tensor(add_3, transpose_11);  add_3 = transpose_11 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:45 in forward, code: x = self.dwconv(x)
            conv1d_6: "f32[512, 512, 7]" = torch.ops.aten.conv1d.default(add_4, p_l__vocos____modules__backbone___convnext_5_dwconv_weight, p_l__vocos____modules__backbone___convnext_5_dwconv_bias, [1], [3], [1], 512);  p_l__vocos____modules__backbone___convnext_5_dwconv_weight = p_l__vocos____modules__backbone___convnext_5_dwconv_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:46 in forward, code: x = x.transpose(1, 2)  # (B, C, T) -> (B, T, C)
            transpose_12: "f32[512, 7, 512]" = torch.ops.aten.transpose.int(conv1d_6, 1, 2);  conv1d_6 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:51 in forward, code: x = self.norm(x)
            layer_norm_6: "f32[512, 7, 512]" = torch.ops.aten.layer_norm.default(transpose_12, [512], p_l__vocos____modules__backbone___convnext_5_norm_weight, p_l__vocos____modules__backbone___convnext_5_norm_bias, 1e-06);  transpose_12 = p_l__vocos____modules__backbone___convnext_5_norm_weight = p_l__vocos____modules__backbone___convnext_5_norm_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:52 in forward, code: x = self.pwconv1(x)
            linear_10: "f32[512, 7, 1536]" = torch.ops.aten.linear.default(layer_norm_6, p_l__vocos____modules__backbone___convnext_5_pwconv1_weight, p_l__vocos____modules__backbone___convnext_5_pwconv1_bias);  layer_norm_6 = p_l__vocos____modules__backbone___convnext_5_pwconv1_weight = p_l__vocos____modules__backbone___convnext_5_pwconv1_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:53 in forward, code: x = self.act(x)
            gelu_5: "f32[512, 7, 1536]" = torch.ops.aten.gelu.default(linear_10);  linear_10 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:54 in forward, code: x = self.pwconv2(x)
            linear_11: "f32[512, 7, 512]" = torch.ops.aten.linear.default(gelu_5, p_l__vocos____modules__backbone___convnext_5_pwconv2_weight, p_l__vocos____modules__backbone___convnext_5_pwconv2_bias);  gelu_5 = p_l__vocos____modules__backbone___convnext_5_pwconv2_weight = p_l__vocos____modules__backbone___convnext_5_pwconv2_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:56 in forward, code: x = self.gamma * x
            mul_5: "f32[512, 7, 512]" = torch.ops.aten.mul.Tensor(p_l__vocos____modules__backbone___convnext_5_gamma, linear_11);  p_l__vocos____modules__backbone___convnext_5_gamma = linear_11 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:57 in forward, code: x = x.transpose(1, 2)  # (B, T, C) -> (B, C, T)
            transpose_13: "f32[512, 512, 7]" = torch.ops.aten.transpose.int(mul_5, 1, 2);  mul_5 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:59 in forward, code: x = residual + x
            add_5: "f32[512, 512, 7]" = torch.ops.aten.add.Tensor(add_4, transpose_13);  add_4 = transpose_13 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:45 in forward, code: x = self.dwconv(x)
            conv1d_7: "f32[512, 512, 7]" = torch.ops.aten.conv1d.default(add_5, p_l__vocos____modules__backbone___convnext_6_dwconv_weight, p_l__vocos____modules__backbone___convnext_6_dwconv_bias, [1], [3], [1], 512);  p_l__vocos____modules__backbone___convnext_6_dwconv_weight = p_l__vocos____modules__backbone___convnext_6_dwconv_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:46 in forward, code: x = x.transpose(1, 2)  # (B, C, T) -> (B, T, C)
            transpose_14: "f32[512, 7, 512]" = torch.ops.aten.transpose.int(conv1d_7, 1, 2);  conv1d_7 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:51 in forward, code: x = self.norm(x)
            layer_norm_7: "f32[512, 7, 512]" = torch.ops.aten.layer_norm.default(transpose_14, [512], p_l__vocos____modules__backbone___convnext_6_norm_weight, p_l__vocos____modules__backbone___convnext_6_norm_bias, 1e-06);  transpose_14 = p_l__vocos____modules__backbone___convnext_6_norm_weight = p_l__vocos____modules__backbone___convnext_6_norm_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:52 in forward, code: x = self.pwconv1(x)
            linear_12: "f32[512, 7, 1536]" = torch.ops.aten.linear.default(layer_norm_7, p_l__vocos____modules__backbone___convnext_6_pwconv1_weight, p_l__vocos____modules__backbone___convnext_6_pwconv1_bias);  layer_norm_7 = p_l__vocos____modules__backbone___convnext_6_pwconv1_weight = p_l__vocos____modules__backbone___convnext_6_pwconv1_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:53 in forward, code: x = self.act(x)
            gelu_6: "f32[512, 7, 1536]" = torch.ops.aten.gelu.default(linear_12);  linear_12 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:54 in forward, code: x = self.pwconv2(x)
            linear_13: "f32[512, 7, 512]" = torch.ops.aten.linear.default(gelu_6, p_l__vocos____modules__backbone___convnext_6_pwconv2_weight, p_l__vocos____modules__backbone___convnext_6_pwconv2_bias);  gelu_6 = p_l__vocos____modules__backbone___convnext_6_pwconv2_weight = p_l__vocos____modules__backbone___convnext_6_pwconv2_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:56 in forward, code: x = self.gamma * x
            mul_6: "f32[512, 7, 512]" = torch.ops.aten.mul.Tensor(p_l__vocos____modules__backbone___convnext_6_gamma, linear_13);  p_l__vocos____modules__backbone___convnext_6_gamma = linear_13 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:57 in forward, code: x = x.transpose(1, 2)  # (B, T, C) -> (B, C, T)
            transpose_15: "f32[512, 512, 7]" = torch.ops.aten.transpose.int(mul_6, 1, 2);  mul_6 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:59 in forward, code: x = residual + x
            add_6: "f32[512, 512, 7]" = torch.ops.aten.add.Tensor(add_5, transpose_15);  add_5 = transpose_15 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:45 in forward, code: x = self.dwconv(x)
            conv1d_8: "f32[512, 512, 7]" = torch.ops.aten.conv1d.default(add_6, p_l__vocos____modules__backbone___convnext_7_dwconv_weight, p_l__vocos____modules__backbone___convnext_7_dwconv_bias, [1], [3], [1], 512);  p_l__vocos____modules__backbone___convnext_7_dwconv_weight = p_l__vocos____modules__backbone___convnext_7_dwconv_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:46 in forward, code: x = x.transpose(1, 2)  # (B, C, T) -> (B, T, C)
            transpose_16: "f32[512, 7, 512]" = torch.ops.aten.transpose.int(conv1d_8, 1, 2);  conv1d_8 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:51 in forward, code: x = self.norm(x)
            layer_norm_8: "f32[512, 7, 512]" = torch.ops.aten.layer_norm.default(transpose_16, [512], p_l__vocos____modules__backbone___convnext_7_norm_weight, p_l__vocos____modules__backbone___convnext_7_norm_bias, 1e-06);  transpose_16 = p_l__vocos____modules__backbone___convnext_7_norm_weight = p_l__vocos____modules__backbone___convnext_7_norm_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:52 in forward, code: x = self.pwconv1(x)
            linear_14: "f32[512, 7, 1536]" = torch.ops.aten.linear.default(layer_norm_8, p_l__vocos____modules__backbone___convnext_7_pwconv1_weight, p_l__vocos____modules__backbone___convnext_7_pwconv1_bias);  layer_norm_8 = p_l__vocos____modules__backbone___convnext_7_pwconv1_weight = p_l__vocos____modules__backbone___convnext_7_pwconv1_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:53 in forward, code: x = self.act(x)
            gelu_7: "f32[512, 7, 1536]" = torch.ops.aten.gelu.default(linear_14);  linear_14 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:54 in forward, code: x = self.pwconv2(x)
            linear_15: "f32[512, 7, 512]" = torch.ops.aten.linear.default(gelu_7, p_l__vocos____modules__backbone___convnext_7_pwconv2_weight, p_l__vocos____modules__backbone___convnext_7_pwconv2_bias);  gelu_7 = p_l__vocos____modules__backbone___convnext_7_pwconv2_weight = p_l__vocos____modules__backbone___convnext_7_pwconv2_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:56 in forward, code: x = self.gamma * x
            mul_7: "f32[512, 7, 512]" = torch.ops.aten.mul.Tensor(p_l__vocos____modules__backbone___convnext_7_gamma, linear_15);  p_l__vocos____modules__backbone___convnext_7_gamma = linear_15 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:57 in forward, code: x = x.transpose(1, 2)  # (B, T, C) -> (B, C, T)
            transpose_17: "f32[512, 512, 7]" = torch.ops.aten.transpose.int(mul_7, 1, 2);  mul_7 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/modules.py:59 in forward, code: x = residual + x
            add_7: "f32[512, 512, 7]" = torch.ops.aten.add.Tensor(add_6, transpose_17);  add_6 = transpose_17 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/models.py:88 in forward, code: x = self.final_layer_norm(x.transpose(1, 2))
            transpose_18: "f32[512, 7, 512]" = torch.ops.aten.transpose.int(add_7, 1, 2);  add_7 = None
            layer_norm_9: "f32[512, 7, 512]" = torch.ops.aten.layer_norm.default(transpose_18, [512], p_l__vocos____modules__backbone___final_layer_norm_weight, p_l__vocos____modules__backbone___final_layer_norm_bias, 1e-06);  transpose_18 = p_l__vocos____modules__backbone___final_layer_norm_weight = p_l__vocos____modules__backbone___final_layer_norm_bias = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/heads.py:55 in forward, code: x = self.out(x).transpose(1, 2)
            linear_16: "f32[512, 7, 1026]" = torch.ops.aten.linear.default(layer_norm_9, p_l__vocos____modules__head___out_weight, p_l__vocos____modules__head___out_bias);  layer_norm_9 = p_l__vocos____modules__head___out_weight = p_l__vocos____modules__head___out_bias = None
            transpose_19: "f32[512, 1026, 7]" = torch.ops.aten.transpose.int(linear_16, 1, 2);  linear_16 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/heads.py:56 in forward, code: mag, p = x.chunk(2, dim=1)
            split = torch.ops.aten.split.Tensor(transpose_19, 513, 1);  transpose_19 = None
            getitem: "f32[512, 513, 7]" = split[0]
            getitem_1: "f32[512, 513, 7]" = split[1];  split = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/heads.py:57 in forward, code: mag = torch.exp(mag)
            exp: "f32[512, 513, 7]" = torch.ops.aten.exp.default(getitem);  getitem = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/heads.py:58 in forward, code: mag = torch.clip(mag, max=1e2)  # safeguard to prevent excessively large magnitudes
            clip: "f32[512, 513, 7]" = torch.ops.aten.clip.default(exp, None, 100.0);  exp = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/heads.py:60 in forward, code: x = torch.cos(p)
            cos: "f32[512, 513, 7]" = torch.ops.aten.cos.default(getitem_1)
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/heads.py:61 in forward, code: y = torch.sin(p)
            sin: "f32[512, 513, 7]" = torch.ops.aten.sin.default(getitem_1);  getitem_1 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/heads.py:67 in forward, code: S = mag * (x + 1j * y)
            mul_8: "c64[512, 513, 7]" = torch.ops.aten.mul.Tensor(sin, 1j);  sin = None
            add_8: "c64[512, 513, 7]" = torch.ops.aten.add.Tensor(cos, mul_8);  cos = mul_8 = None
            mul_9: "c64[512, 513, 7]" = torch.ops.aten.mul.Tensor(clip, add_8);  clip = add_8 = None
            
             # File: /home/ubuntu/projects/f5-tts/venv/lib/python3.12/site-packages/vocos/spectral_ops.py:46 in forward, code: return torch.istft(spec, self.n_fft, self.hop_length, self.win_length, self.window, center=True)
            istft: "f32[512, 1536]" = torch.ops.aten.istft.default(mul_9, 1024, 256, 1024, b_l__vocos____modules__head___istft_window);  mul_9 = b_l__vocos____modules__head___istft_window = None
            return (istft,)
            
Graph signature: ExportGraphSignature(input_specs=[InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_0_gamma'), target='backbone.convnext.0.gamma', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_1_gamma'), target='backbone.convnext.1.gamma', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_2_gamma'), target='backbone.convnext.2.gamma', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_3_gamma'), target='backbone.convnext.3.gamma', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_4_gamma'), target='backbone.convnext.4.gamma', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_5_gamma'), target='backbone.convnext.5.gamma', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_6_gamma'), target='backbone.convnext.6.gamma', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_7_gamma'), target='backbone.convnext.7.gamma', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___embed_weight'), target='backbone.embed.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___embed_bias'), target='backbone.embed.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___norm_weight'), target='backbone.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___norm_bias'), target='backbone.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_0_dwconv_weight'), target='backbone.convnext.0.dwconv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_0_dwconv_bias'), target='backbone.convnext.0.dwconv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_0_norm_weight'), target='backbone.convnext.0.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_0_norm_bias'), target='backbone.convnext.0.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_0_pwconv1_weight'), target='backbone.convnext.0.pwconv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_0_pwconv1_bias'), target='backbone.convnext.0.pwconv1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_0_pwconv2_weight'), target='backbone.convnext.0.pwconv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_0_pwconv2_bias'), target='backbone.convnext.0.pwconv2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_1_dwconv_weight'), target='backbone.convnext.1.dwconv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_1_dwconv_bias'), target='backbone.convnext.1.dwconv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_1_norm_weight'), target='backbone.convnext.1.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_1_norm_bias'), target='backbone.convnext.1.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_1_pwconv1_weight'), target='backbone.convnext.1.pwconv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_1_pwconv1_bias'), target='backbone.convnext.1.pwconv1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_1_pwconv2_weight'), target='backbone.convnext.1.pwconv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_1_pwconv2_bias'), target='backbone.convnext.1.pwconv2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_2_dwconv_weight'), target='backbone.convnext.2.dwconv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_2_dwconv_bias'), target='backbone.convnext.2.dwconv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_2_norm_weight'), target='backbone.convnext.2.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_2_norm_bias'), target='backbone.convnext.2.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_2_pwconv1_weight'), target='backbone.convnext.2.pwconv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_2_pwconv1_bias'), target='backbone.convnext.2.pwconv1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_2_pwconv2_weight'), target='backbone.convnext.2.pwconv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_2_pwconv2_bias'), target='backbone.convnext.2.pwconv2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_3_dwconv_weight'), target='backbone.convnext.3.dwconv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_3_dwconv_bias'), target='backbone.convnext.3.dwconv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_3_norm_weight'), target='backbone.convnext.3.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_3_norm_bias'), target='backbone.convnext.3.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_3_pwconv1_weight'), target='backbone.convnext.3.pwconv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_3_pwconv1_bias'), target='backbone.convnext.3.pwconv1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_3_pwconv2_weight'), target='backbone.convnext.3.pwconv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_3_pwconv2_bias'), target='backbone.convnext.3.pwconv2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_4_dwconv_weight'), target='backbone.convnext.4.dwconv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_4_dwconv_bias'), target='backbone.convnext.4.dwconv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_4_norm_weight'), target='backbone.convnext.4.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_4_norm_bias'), target='backbone.convnext.4.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_4_pwconv1_weight'), target='backbone.convnext.4.pwconv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_4_pwconv1_bias'), target='backbone.convnext.4.pwconv1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_4_pwconv2_weight'), target='backbone.convnext.4.pwconv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_4_pwconv2_bias'), target='backbone.convnext.4.pwconv2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_5_dwconv_weight'), target='backbone.convnext.5.dwconv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_5_dwconv_bias'), target='backbone.convnext.5.dwconv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_5_norm_weight'), target='backbone.convnext.5.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_5_norm_bias'), target='backbone.convnext.5.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_5_pwconv1_weight'), target='backbone.convnext.5.pwconv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_5_pwconv1_bias'), target='backbone.convnext.5.pwconv1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_5_pwconv2_weight'), target='backbone.convnext.5.pwconv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_5_pwconv2_bias'), target='backbone.convnext.5.pwconv2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_6_dwconv_weight'), target='backbone.convnext.6.dwconv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_6_dwconv_bias'), target='backbone.convnext.6.dwconv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_6_norm_weight'), target='backbone.convnext.6.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_6_norm_bias'), target='backbone.convnext.6.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_6_pwconv1_weight'), target='backbone.convnext.6.pwconv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_6_pwconv1_bias'), target='backbone.convnext.6.pwconv1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_6_pwconv2_weight'), target='backbone.convnext.6.pwconv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_6_pwconv2_bias'), target='backbone.convnext.6.pwconv2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_7_dwconv_weight'), target='backbone.convnext.7.dwconv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_7_dwconv_bias'), target='backbone.convnext.7.dwconv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_7_norm_weight'), target='backbone.convnext.7.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_7_norm_bias'), target='backbone.convnext.7.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_7_pwconv1_weight'), target='backbone.convnext.7.pwconv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_7_pwconv1_bias'), target='backbone.convnext.7.pwconv1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_7_pwconv2_weight'), target='backbone.convnext.7.pwconv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___convnext_7_pwconv2_bias'), target='backbone.convnext.7.pwconv2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___final_layer_norm_weight'), target='backbone.final_layer_norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__backbone___final_layer_norm_bias'), target='backbone.final_layer_norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__head___out_weight'), target='head.out.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_l__vocos____modules__head___out_bias'), target='head.out.bias', persistent=None), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_l__vocos____modules__head___istft_window'), target='head.istft.window', persistent=True), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='x'), target=None, persistent=None)], output_specs=[OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='istft'), target=None)])
Range constraints: {}

```

## Analysis

PyTorch ONNX Conversion Analysis

## Model Information

The model has 13531650 parameters and 1024 buffers (non-trainable parameters).
Number of parameters per dtype:
```python
defaultdict(<class 'int'>, {torch.float32: 13531650})
```
Number of buffers per dtype:
```python
defaultdict(<class 'int'>, {torch.float32: 1024})
```

Inputs:
- `x`: `TensorMetadata(shape=torch.Size([512, 100, 7]), dtype=torch.float32, requires_grad=False, stride=(700, 7, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})`

Outputs:
- `istft`: `TensorMetadata(shape=torch.Size([512, 1536]), dtype=torch.float32, requires_grad=False, stride=(1536, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={})`

The FX graph has 174 nodes in total. Number of FX nodes per op:
- `placeholder`: 82
- `call_function`: 91
- `output`: 1


Of the call_function nodes, the counts of operators used are:

- `aten.transpose.int`: 20
- `aten.linear.default`: 17
- `aten.layer_norm.default`: 10
- `aten.mul.Tensor`: 10
- `aten.conv1d.default`: 9
- `aten.add.Tensor`: 9
- `aten.gelu.default`: 8
- `<built-in function getitem>`: 2
- `aten.split.Tensor`: 1
- `aten.exp.default`: 1
- `aten.clip.default`: 1
- `aten.cos.default`: 1
- `aten.sin.default`: 1
- `aten.istft.default`: 1

## ONNX Conversion Information

The model contains operators the dispatcher could not find registered ONNX decompositions for. This may be due to missing implementations, decompositions not registered correctly, or a bug in the dispatcher.

Errors grouped by operator:

- `aten.linear.default`:     No decompositions registered for the real-valued input. Example node: `%linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%layer_norm_1, %p_l__vocos____modules__backbone___convnext_0_pwconv1_weight, %p_l__vocos____modules__backbone___convnext_0_pwconv1_bias), kwargs = {})`. All nodes: `[linear, linear_1, linear_2, linear_3, linear_4, linear_5, linear_6, linear_7, linear_8, linear_9, linear_10, linear_11, linear_12, linear_13, linear_14, linear_15, linear_16]`
- `aten.istft.default`:     No decompositions registered for the complex-valued input. Example node: `%istft : [num_users=1] = call_function[target=torch.ops.aten.istft.default](args = (%mul_9, 1024, 256, 1024, %b_l__vocos____modules__head___istft_window), kwargs = {})`. All nodes: `[istft]`
- `aten.clip.default`:     No decompositions registered for the real-valued input. Example node: `%clip : [num_users=1] = call_function[target=torch.ops.aten.clip.default](args = (%exp, None, 100.0), kwargs = {})`. All nodes: `[clip]`

## Decomposition comparison

Ops exist only in the ExportedProgram before decomposition: `['aten.clip.default', 'aten.istft.default', 'aten.linear.default']`

Ops exist only in the ExportedProgram after decomposition: `['aten._unsafe_index_put.default', 'aten._unsafe_view.default', 'aten.addmm.default', 'aten.arange.default', 'aten.clamp.default', 'aten.clone.default', 'aten.div.Tensor', 'aten.expand.default', 'aten.new_zeros.default', 'aten.permute.default', 'aten.pow.Tensor_Tensor', 'aten.scalar_tensor.default', 'aten.slice.Tensor', 'aten.t.default', 'aten.unfold.default', 'aten.view.default', 'prims.convert_element_type.default', 'prims.fft_c2r.default']`

